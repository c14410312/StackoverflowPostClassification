{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to categorise posts based on tags\n",
    "\n",
    "* Required to categorise the posts into less granular topics based on the tags related to each post\n",
    "* Assign a category to posts without any tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dbutler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Parse core java topics\n",
    "* site: http://java.meritcampus.com/core-java-topics\n",
    "* extracted the terms from the above website into a file\n",
    "* created the function below to create a dictionary storing the core topic along with a unique list of key terms related to that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topic = True\n",
    "java_topic_dict = {}\n",
    "java_topic = ''\n",
    "tmp_list = []\n",
    "\n",
    "with open('./data/java_topics.txt') as file:\n",
    "    for line in file:   \n",
    "        #create a new topic\n",
    "        if line in '\\n':\n",
    "            java_topic_dict[java_topic] = set(tmp_list)\n",
    "            tmp_list = []\n",
    "            new_topic = True\n",
    "            continue\n",
    "            \n",
    "        if new_topic:\n",
    "            #assign the current line to be the java topic\n",
    "            java_topic = ' '.join(line.split()[1:])\n",
    "            new_topic = False\n",
    "            continue\n",
    "        \n",
    "        #split each line into individual words and append\n",
    "        for el in line.split()[1:]:\n",
    "            #stopword removal\n",
    "            if el not in stopWords and len(el) > 1:\n",
    "                tmp_list.append(el.lower().replace('-', ''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Datatypes', 'Variables', 'Operators', 'Control Statements', 'Methods', 'Arrays', 'Classes', 'Inheritance', 'Methods Overiding, Overloading', 'Abstract Class And Methods', 'Interfaces, Packages and Access Control', 'final, static and others', 'Exceptions', 'Multithreaded Programming', 'Generics', 'Strings', 'java.lang', 'Collections Framework', 'Utility Classes', 'Input/Output', 'The Applet Class', 'Swing', 'Servlets'])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_topic_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of the topic keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "java_topic_keys = list(java_topic_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - eliminate frequently occuring sub terms across various topics  \n",
    "* example the word class appears in a wide variety of topics\n",
    "\n",
    "The function below eliminates all the terms in a given topic that occur in other topics and retains the terms unique to that topic only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the refined topic terms\n",
    "new_java_topic_dict = {}\n",
    "\n",
    "#scan through each topic\n",
    "for key in java_topic_keys:\n",
    "    \n",
    "    #tmp list to hold all the terms related to topic\n",
    "    tmp_list = []\n",
    "    for item in java_topic_keys:\n",
    "        #we do not want to add the terms related to the current topic to the main list\n",
    "        #when detected move on to next\n",
    "        if item == key:\n",
    "            continue\n",
    "        else:\n",
    "            #for each term related to the topic append them to the tmp list\n",
    "            for el in list(java_topic_dict[item]):\n",
    "                tmp_list.append(el)\n",
    "    #create a set form the tmp list containing terms from all the topics except the current topic (key)\n",
    "    #this creates our stop list\n",
    "    stop_list = set(tmp_list)\n",
    "    \n",
    "    #initialise a filtered_list to store unique values for each topic\n",
    "    filtered_list = []\n",
    "    for el in list(java_topic_dict[key]):\n",
    "        #if it doesnt appear in our stop list dont append it\n",
    "        if el not in stop_list:\n",
    "            filtered_list.append(el)\n",
    "\n",
    "    #add the key to the list\n",
    "    filtered_list.append(key.lower())\n",
    "    #creates a new list of unique terms related to that topic. \n",
    "    new_java_topic_dict[key] = filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Attempt to categorise posts in the dataset based on their tag values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/filtered_cleaned_posts_no_frameworks_no_alt_lang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4212, 5)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec function converts the word into a vector\n",
    "def word2vec(word):\n",
    "    from collections import Counter\n",
    "    from math import sqrt\n",
    "\n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    # precomputes a set of the different characters\n",
    "    sw = set(cw)\n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "\n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "# calculates the cosine similarity between 2 vectors i.e. words\n",
    "def cosdis(v1, v2):\n",
    "    # which characters are common to the two words?\n",
    "    common = v1[1].intersection(v2[1])\n",
    "    # by definition of cosine distance we have\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - function to categorise a post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Description:\n",
    "        takes an argument of a list of tags and checks two things:\n",
    "        \n",
    "        1)  checks to see if any of the tags are related directly to a core topic e.g. generics, classes, exceptions\n",
    "            if the score is greater than 95% then it returns the key that the tag scored greater than 95% against.\n",
    "        \n",
    "        2)  If there is no match over 95% for the keys, the tags are then compared to each of the terms in all \n",
    "            of the topics, each topics terms are loaded in and the cosine similarity is checked against each word\n",
    "            the highest scoring word is stored. For example if there are three tags, each tag will be compared to the \n",
    "            rest of the terms in a given topic. The highest score for each tag is appended to a total score, \n",
    "            this generates a percentage of how likely it is related to that topic. The highest scoring topic is returned\n",
    "    \n",
    "    args: tag_list\n",
    "        list of tags related to a given post\n",
    "        \n",
    "'''\n",
    "def assign_java_topic(tag_list):\n",
    "    \n",
    "    #first check if it contains a core topic tag\n",
    "    for tag in tag_list:\n",
    "        va = word2vec(tag)\n",
    "        for jkey in java_topic_keys:\n",
    "            vb = word2vec(jkey.lower())\n",
    "            #if the cosine similarity is greater than 95% return that key as the category\n",
    "            if cosdis(va, vb) > 0.95:\n",
    "                return jkey, cosdis(va,vb)\n",
    "\n",
    "    #stores the most likely topic\n",
    "    max_topic_name = ''\n",
    "    #holds the max topic score for the set of tags\n",
    "    max_topic_score = 0\n",
    "\n",
    "    for key in java_topic_keys:\n",
    "        #stores the score of the current topic\n",
    "        topic_score = 0\n",
    "        #each tag is converted to a vector\n",
    "        for tag in tag_list:\n",
    "            va = word2vec(tag)\n",
    "            max_tag_score = 0\n",
    "\n",
    "            #for every element in the current topic e.g. classes\n",
    "            for el in new_java_topic_dict[key]:\n",
    "                #vb is the current term in the current topic converted to vector format\n",
    "                vb = word2vec(el)\n",
    "                #calculate the cosine similarity\n",
    "                score = cosdis(va,vb)\n",
    "\n",
    "                #if the score is greater than the current max tag score then \n",
    "                # assign this as the new max\n",
    "                if score > max_tag_score:\n",
    "                    max_tag_score = score\n",
    "            #increment the overall topic score using the max tag score\n",
    "            topic_score += max_tag_score\n",
    "            \n",
    "        #check if this is the highest scoring topic score\n",
    "        if topic_score > max_topic_score:\n",
    "            max_topic_score = topic_score\n",
    "            max_topic_name = key\n",
    "    \n",
    "    #returns the highest scoring topic along with the score as a percentage. \n",
    "    return max_topic_name, max_topic_score/len(tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Test the function against some posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exception', 'mocking', 'try-catch']\n",
      "Exceptions\n",
      "0.9574271077563381\n",
      "\n",
      "\n",
      "['generics', 'syntax']\n",
      "Generics\n",
      "0.9999999999999999\n",
      "\n",
      "\n",
      "['-ee', 'jvm', 'out-of-memory', 'heap-memory']\n",
      "Classes\n",
      "0.6780554429224603\n",
      "\n",
      "\n",
      "['string', 'random', 'alphanumeric']\n",
      "Strings\n",
      "0.9525793444156805\n",
      "\n",
      "\n",
      "['class', 'clone']\n",
      "Classes\n",
      "0.8590265111456049\n",
      "\n",
      "\n",
      "['generics']\n",
      "Generics\n",
      "0.9999999999999999\n",
      "\n",
      "\n",
      "['interface', 'static']\n",
      "Operators\n",
      "0.8423850737154739\n",
      "\n",
      "\n",
      "['string']\n",
      "Strings\n",
      "0.9525793444156805\n",
      "\n",
      "\n",
      "['multithreading', 'memory-leaks']\n",
      "Multithreaded Programming\n",
      "0.7731429659309266\n",
      "\n",
      "\n",
      "['arrays', 'data-structures', 'data-manipulation']\n",
      "Arrays\n",
      "0.9999999999999999\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():   \n",
    "    topic_name, topic_score = assign_java_topic(test.loc[index, 'Tags'].split())\n",
    "    print(test.loc[index, 'Tags'].split())\n",
    "    print(topic_name)\n",
    "    print(topic_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections Framework\n",
      "0.8619711265030845\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
