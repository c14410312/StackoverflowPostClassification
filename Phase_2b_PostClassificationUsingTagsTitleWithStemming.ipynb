{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traninig and Classifying with title and tags chunks\n",
    "\n",
    "In this experiment I will be analysing the results of two techniques. I will first be using the tags only as input into the classification models. Then I will be combining the tags and the title per post and analysing the differences, whether or not this improved the accuracy.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. clean the tags from <[tag]> format to [tag] (removing the angle brackets)\n",
    "2. merge the tags and the titles into a single chunk\n",
    "3. Drop all words to lowercase\n",
    "4. Extract features using a CounterVectorizer instance\n",
    "5. Train and evaluate various classification models:\n",
    "    * Naive Bayes \n",
    "    * Naive Bayes n-grams\n",
    "    * Naive Bayes n-grams TF-IDF\n",
    "    * Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "df = pandas.read_csv('./data/procedural_casual_Q_1500_SO_Java.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13225</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;I've recently inherited a internationalized...</td>\n",
       "      <td>How can I refactor HTML markup out of my prope...</td>\n",
       "      <td>&lt;java&gt;&lt;jsp&gt;&lt;internationalization&gt;&lt;struts&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24991</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;p&gt;I have defined a Java function:&lt;/p&gt;\\n\\n&lt;pre...</td>\n",
       "      <td>Why can't I explicitly pass the type argument ...</td>\n",
       "      <td>&lt;java&gt;&lt;generics&gt;&lt;syntax&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24866</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;p&gt;I am using Java back end for creating an XM...</td>\n",
       "      <td>Is it essential that I use libraries to manipu...</td>\n",
       "      <td>&lt;java&gt;&lt;xml&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25449</td>\n",
       "      <td>29</td>\n",
       "      <td>&lt;p&gt;I want to create a Java program that can be...</td>\n",
       "      <td>How to create a pluginable Java program?</td>\n",
       "      <td>&lt;java&gt;&lt;plugins&gt;&lt;plugin-architecture&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26305</td>\n",
       "      <td>151</td>\n",
       "      <td>&lt;p&gt;I want to be able to play sound files in my...</td>\n",
       "      <td>How can I play sound in Java?</td>\n",
       "      <td>&lt;java&gt;&lt;audio&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>262318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Score                                               Body  \\\n",
       "0  13225      8  <p>I've recently inherited a internationalized...   \n",
       "1  24991     19  <p>I have defined a Java function:</p>\\n\\n<pre...   \n",
       "2  24866     11  <p>I am using Java back end for creating an XM...   \n",
       "3  25449     29  <p>I want to create a Java program that can be...   \n",
       "4  26305    151  <p>I want to be able to play sound files in my...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I refactor HTML markup out of my prope...   \n",
       "1  Why can't I explicitly pass the type argument ...   \n",
       "2  Is it essential that I use libraries to manipu...   \n",
       "3           How to create a pluginable Java program?   \n",
       "4                      How can I play sound in Java?   \n",
       "\n",
       "                                        Tags  AnswerCount  CommentCount  \\\n",
       "0  <java><jsp><internationalization><struts>            4             0   \n",
       "1                   <java><generics><syntax>            4             1   \n",
       "2                                <java><xml>           11             0   \n",
       "3       <java><plugins><plugin-architecture>            6             1   \n",
       "4                              <java><audio>            9             1   \n",
       "\n",
       "   FavoriteCount  ViewCount  OK  \n",
       "0            NaN       2078   0  \n",
       "1            6.0      21171   1  \n",
       "2            NaN        690   0  \n",
       "3           18.0      17544   1  \n",
       "4           57.0     262318   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Training and Evaluating - Tags Only!\n",
    "\n",
    "## Create a new dataframe with only tags and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df[['Tags', 'OK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <java><jsp><internationalization><struts>\n",
       "1                     <java><generics><syntax>\n",
       "2                                  <java><xml>\n",
       "3         <java><plugins><plugin-architecture>\n",
       "4                                <java><audio>\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.Tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_new['cleaned_tags'] = \"\"\n",
    "for index, row in df_new.iterrows():\n",
    "    cleaned_tags = df_new.loc[index, 'Tags'].replace('>', \" \").replace('<', \" \").replace('java', '')\n",
    "    df_new.loc[index, 'cleaned_tags'] = cleaned_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['Tags'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traninig models on tags only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['cleaned_tags'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['cleaned_tags'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.813187302328\n",
      "Confusion matrix:\n",
      "[[781  86]\n",
      " [140 492]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['cleaned_tags'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['cleaned_tags'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.816174667223\n",
      "Confusion matrix:\n",
      "[[783  84]\n",
      " [139 493]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer('''ngram_range=(1, 2)''')),\n",
    "    ('tfidf_transformer', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['cleaned_tags'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['cleaned_tags'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.804761296112\n",
      "Confusion matrix:\n",
      "[[791  76]\n",
      " [155 477]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('classifier', BernoulliNB(binarize=0.3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['cleaned_tags'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['cleaned_tags'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.806190380159\n",
      "Confusion matrix:\n",
      "[[769  98]\n",
      " [138 494]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the tags with title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new['title'] = \"\"\n",
    "\n",
    "for index, row in df_new.iterrows():\n",
    "        \n",
    "        df_new.loc[index, 'title'] = df.loc[index, 'Title']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new['title_tag_chunk'] = df_new[df_new.columns[1:3]].apply(lambda x: ','.join(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new.title_tag_chunk = df_new.title_tag_chunk.apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['cleaned_tags', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop thorugh the data frame\n",
    "for index, row in df_new.iterrows():\n",
    "    \n",
    "    #target chunk of data\n",
    "    words = row['title_tag_chunk']\n",
    "    tmp =[]\n",
    "    for word in words.split():\n",
    "        #lemmatise\n",
    "        word = stemmer.stem(word)\n",
    "        tmp.append(word)\n",
    "    df_new.loc[index, 'title_tag_chunk'] = ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['title_tag_chunk'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['title_tag_chunk'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.855323483373\n",
      "Confusion matrix:\n",
      "[[762 105]\n",
      " [ 77 555]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open('./models/multinomialnb_post_classifier_title_tag.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\"how to efficiently iterate over each entry in a map\", \"how to add local jar files to a maven project\"]\n",
    "pipeline.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['title_tag_chunk'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['title_tag_chunk'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.852974814957\n",
      "Confusion matrix:\n",
      "[[763 104]\n",
      " [ 81 551]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open('./models/multinomialnb_classifier_ngrams_title_tag.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer('''ngram_range=(1, 2)''')),\n",
    "    ('tfidf_transformer', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['title_tag_chunk'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['title_tag_chunk'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.840610880414\n",
      "Confusion matrix:\n",
      "[[785  82]\n",
      " [112 520]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('classifier', BernoulliNB(binarize=0.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['title_tag_chunk'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['title_tag_chunk'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.829413991311\n",
      "Confusion matrix:\n",
      "[[761 106]\n",
      " [106 526]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports\n",
    "\n",
    "## Tags-only\n",
    "\n",
    "| Classifier               | Features           | F1-Score       | TN  | FP | FN  | TP  |\n",
    "|--------------------------|--------------------|----------------|-----|----|-----|-----|\n",
    "| Multi-nomial Naive Bayes | Bag-of-words       | 0.813187302328 | 781 | 86 | 140 | 492 |\n",
    "| Multi-nomial Naive Bayes | Bigram Counts      | 0.816174667223 | 783 | 84 | 139 | 493 |\n",
    "| Multi-nomial Naive Bayes | Bigram Frequencies | 0.804761296112 | 791 | 76 | 155 | 477 |\n",
    "| Bernoulli Naive Bayes    | Bigram Occurences  | 0.806190380159 | 769 | 98 | 138 | 494 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags-Titles Chunked\n",
    "\n",
    "| Classifier               | Features           | F1-Score       | TN  | FP  | FN  | TP  |\n",
    "|--------------------------|--------------------|----------------|-----|-----|-----|-----|\n",
    "| Multi-nomial Naive Bayes | Bag-of-words       | 0.861472066928 | 764 | 103 | 72  | 560 |\n",
    "| Multi-nomial Naive Bayes | Bigram Counts      | 0.856620216331 | 766 | 101 | 79  | 553 |\n",
    "| Multi-nomial Naive Bayes | Bigram Frequencies | 0.844687424368 | 789 | 78  | 110 | 552 |\n",
    "| Bernoulli Naive Bayes    | Bigram Occurences  | 0.83271814222  | 766 | 101 | 105 | 527 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
