{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post classification Experiment using Scikit learn\n",
    "\n",
    "* Date 20/02/18\n",
    "* Dylan Butler\n",
    "\n",
    "## Task\n",
    "The overall task of this experiment is to create a trained classifier to correctly classify whether or not a post is useful for quizes and knowledge testing of Java core concepts.\n",
    "\n",
    "## Data\n",
    "The data for this experiment consists of a manually labelled dataset of 1500 stackoverflow posts. These posts have been filtered according to the following characteristics:\n",
    "\n",
    "* They posses the structure of either a \"how-to\"(procedural intent) or a \"why\"(casual intent) type of question\n",
    "* They have a minimum score of 7 (post score)\n",
    "* They have not been deleted\n",
    "* They have not been closed\n",
    "* They have an accepted answer\n",
    "\n",
    "After extracting this data I conducted an analysis on the resulting dataset to gain a deeper understanding of the data:\n",
    "\n",
    "### Extracted Data insights\n",
    "* Group 1 (useful for quizzes):\n",
    "    * How to split a string in Java?\n",
    "    * Read and convert an input stream to a string?\n",
    "    * How to read all files in a folder in Java?\n",
    "    * How to round a number to n decimal places in Java?\n",
    "    * How to parse JSON in Java?\n",
    "    * How do I declare and initialize an array in Java?\n",
    "    * Why is it faster to process an unsorted array vs a sorted array\n",
    "    * How do I compare strings in Java?\n",
    "* Group 2 (not useful fr quizzes):\n",
    "    * How do I fix android.os.NetworkOnMainThreadException?\n",
    "    * How do you assert that a certain exception is thrown in JUnit 4 tests?\n",
    "    * How to fix java.lang.UnsupportedClassVersionError: Unsupported major.minor version\n",
    "    * How to add local jar files to a Maven project?\n",
    "    * How do I set up IntelliJ IDEA for Android applications?\n",
    "    * How does autowiring work in Spring?\n",
    "    * How do I tell Maven to use the latest version of a dependency?\n",
    "    * Unfortunately MyApp has stopped. How can I solve this?\n",
    "    * Why is subtracting these two times (in 1927) giving a strange result?\n",
    "\n",
    "### Key Findings\n",
    "* Useless Q's\n",
    "    * A key difference I can spot is that most of the questions that pose no use are environment, framework, related and focus on a technology that uses Java.\n",
    "    * Verbs like; set-up, fix, stopped ... i.e. less java specific and more generic - used in everyday language. \n",
    "* Useful Q's\n",
    "    * The useful questions seem to be following a pattern in which the main words in the questions (split, string, read, java, JSON, declare, initialize) are all words closely related to Java and programming concepts in general.  \n",
    "    * The verbs/action words used in the useful q's are closely associated with java itself.\n",
    "    \n",
    "    \n",
    "# Experiment Process\n",
    "\n",
    "1. Chunk titles and bodies into a single body\n",
    "    * eliminate code snippets \n",
    "    * remove stop words\n",
    "    * lemmatise each body\n",
    "2. Extract the core features from the text that the algorithm can learn from\n",
    "3. Train a classifier\n",
    "4. Evaluate\n",
    "5. Improve results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1) Generating the data\n",
    "The format I will converting the data into for this first experiment will be flattened chunks of (tags, title and body) of each post. \n",
    "\n",
    "1. Remove all the code snippets from the bodys and titles of the  text --> using BeautifulSoup\n",
    "2. Merge the title, bodies into a single chunk\n",
    "3. remove all stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "df = pandas.read_csv('./data/procedural_casual_Q_1500_SO_Java.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13225</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;I've recently inherited a internationalized...</td>\n",
       "      <td>How can I refactor HTML markup out of my prope...</td>\n",
       "      <td>&lt;java&gt;&lt;jsp&gt;&lt;internationalization&gt;&lt;struts&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24991</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;p&gt;I have defined a Java function:&lt;/p&gt;\\n\\n&lt;pre...</td>\n",
       "      <td>Why can't I explicitly pass the type argument ...</td>\n",
       "      <td>&lt;java&gt;&lt;generics&gt;&lt;syntax&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24866</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;p&gt;I am using Java back end for creating an XM...</td>\n",
       "      <td>Is it essential that I use libraries to manipu...</td>\n",
       "      <td>&lt;java&gt;&lt;xml&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25449</td>\n",
       "      <td>29</td>\n",
       "      <td>&lt;p&gt;I want to create a Java program that can be...</td>\n",
       "      <td>How to create a pluginable Java program?</td>\n",
       "      <td>&lt;java&gt;&lt;plugins&gt;&lt;plugin-architecture&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26305</td>\n",
       "      <td>151</td>\n",
       "      <td>&lt;p&gt;I want to be able to play sound files in my...</td>\n",
       "      <td>How can I play sound in Java?</td>\n",
       "      <td>&lt;java&gt;&lt;audio&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>262318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Score                                               Body  \\\n",
       "0  13225      8  <p>I've recently inherited a internationalized...   \n",
       "1  24991     19  <p>I have defined a Java function:</p>\\n\\n<pre...   \n",
       "2  24866     11  <p>I am using Java back end for creating an XM...   \n",
       "3  25449     29  <p>I want to create a Java program that can be...   \n",
       "4  26305    151  <p>I want to be able to play sound files in my...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How can I refactor HTML markup out of my prope...   \n",
       "1  Why can't I explicitly pass the type argument ...   \n",
       "2  Is it essential that I use libraries to manipu...   \n",
       "3           How to create a pluginable Java program?   \n",
       "4                      How can I play sound in Java?   \n",
       "\n",
       "                                        Tags  AnswerCount  CommentCount  \\\n",
       "0  <java><jsp><internationalization><struts>            4             0   \n",
       "1                   <java><generics><syntax>            4             1   \n",
       "2                                <java><xml>           11             0   \n",
       "3       <java><plugins><plugin-architecture>            6             1   \n",
       "4                              <java><audio>            9             1   \n",
       "\n",
       "   FavoriteCount  ViewCount  OK  \n",
       "0            NaN       2078   0  \n",
       "1            6.0      21171   1  \n",
       "2            NaN        690   0  \n",
       "3           18.0      17544   1  \n",
       "4           57.0     262318   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge each posts body and title into a single chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Body', 'Title'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merges title and body into a single chunk\n",
    "df['Title_Body_Chunk'] = df[df.columns[2:4]].apply(lambda x: ','.join(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _remove_attrs(soup):\n",
    "    for tag in soup.findAll(True): \n",
    "        tag.attrs = None\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialise a new column\n",
    "df['cleaned_body_title'] = \"\"\n",
    "\n",
    "# loop thorugh the data frame\n",
    "for index, row in df.iterrows():\n",
    "        \n",
    "        #print(row.Title_Body_Chunk)\n",
    "        \n",
    "        soup = BeautifulSoup(row['Title_Body_Chunk'], 'html5lib')\n",
    "        \n",
    "        for code in soup.find_all(\"code\"):\n",
    "            code.decompose()\n",
    "        cleaned = soup.get_text()\n",
    "        \n",
    "        #create a new column to hold the cleaned data\n",
    "        df.loc[index, \"cleaned_body_title\"] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Title', 'Body', 'Title_Body_Chunk'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>OK</th>\n",
       "      <th>cleaned_body_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13225</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;java&gt;&lt;jsp&gt;&lt;internationalization&gt;&lt;struts&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2078</td>\n",
       "      <td>0</td>\n",
       "      <td>I've recently inherited a internationalized an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24991</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;java&gt;&lt;generics&gt;&lt;syntax&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21171</td>\n",
       "      <td>1</td>\n",
       "      <td>I have defined a Java function:\\n\\n\\n\\nOne way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24866</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;java&gt;&lt;xml&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "      <td>I am using Java back end for creating an XML s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25449</td>\n",
       "      <td>29</td>\n",
       "      <td>&lt;java&gt;&lt;plugins&gt;&lt;plugin-architecture&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17544</td>\n",
       "      <td>1</td>\n",
       "      <td>I want to create a Java program that can be ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26305</td>\n",
       "      <td>151</td>\n",
       "      <td>&lt;java&gt;&lt;audio&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>262318</td>\n",
       "      <td>1</td>\n",
       "      <td>I want to be able to play sound files in my pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Score                                       Tags  AnswerCount  \\\n",
       "0  13225      8  <java><jsp><internationalization><struts>            4   \n",
       "1  24991     19                   <java><generics><syntax>            4   \n",
       "2  24866     11                                <java><xml>           11   \n",
       "3  25449     29       <java><plugins><plugin-architecture>            6   \n",
       "4  26305    151                              <java><audio>            9   \n",
       "\n",
       "   CommentCount  FavoriteCount  ViewCount  OK  \\\n",
       "0             0            NaN       2078   0   \n",
       "1             1            6.0      21171   1   \n",
       "2             0            NaN        690   0   \n",
       "3             1           18.0      17544   1   \n",
       "4             1           57.0     262318   1   \n",
       "\n",
       "                                  cleaned_body_title  \n",
       "0  I've recently inherited a internationalized an...  \n",
       "1  I have defined a Java function:\\n\\n\\n\\nOne way...  \n",
       "2  I am using Java back end for creating an XML s...  \n",
       "3  I want to create a Java program that can be ex...  \n",
       "4  I want to be able to play sound files in my pr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a Dataframe with only the classification and the chunk of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df[['cleaned_body_title', 'OK']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove all stopwords and lemmatise remaining values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dbutler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dbutler/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#initialise a new column\n",
    "df_new['text'] = \"\"\n",
    "\n",
    "# loop thorugh the data frame\n",
    "for index, row in df_new.iterrows():\n",
    "    \n",
    "    #target chunk of data\n",
    "    words = row['cleaned_body_title']\n",
    "    tmp =[]\n",
    "    for word in words.split():\n",
    "        #stopword removal\n",
    "        if word not in stopWords:\n",
    "            #lemmatise\n",
    "            word = wordnet_lemmatizer.lemmatize(word)\n",
    "            tmp.append(word)\n",
    "    df_new.loc[index, 'text'] = ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['cleaned_body_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OK</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I've recently inherited internationalized text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I defined Java function: One way call like so:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I using Java back end creating XML string pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I want create Java program extended plugins. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I want able play sound file program. Where I l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OK                                               text\n",
       "0   0  I've recently inherited internationalized text...\n",
       "1   1  I defined Java function: One way call like so:...\n",
       "2   0  I using Java back end creating XML string pass...\n",
       "3   1  I want create Java program extended plugins. H...\n",
       "4   1  I want able play sound file program. Where I l..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Extracting Features from the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "counts = cv.fit_transform(df_new['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1499x7752 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 60069 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list all of the elements in the CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Classifying the Posts\n",
    "\n",
    "The first classifier I will be implementing is a naive bayes classifier. Bayes theorom - each feature (in this case word counts) is independent from every other one and each one contributes to the probability that an example belongs to a particular class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Initialize and train a new MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#targets are the OK column in the df_new dataframe above\n",
    "targets = df_new['OK'].values\n",
    "#train the NB classifier\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test out the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = [\"How do I explicitly pass the type argument to a generic Java method? I do not understand how to achieve this\", \"How do I generate a new eclipse project? I am trying to create a new eclipse project and I need help setting it up\"]\n",
    "example_counts = cv.transform(examples)\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on the above:\n",
    "\n",
    "The predictor can correctly classify between the two examples that were generated using the chunk of text provided for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining - connecting the process\n",
    "\n",
    "a pipeline can be introduced to merge both the feature extraction and classification into one operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(df_new['text'].values, df_new['OK'].values)\n",
    "pipeline.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Cross-validating the model - K-fold\n",
    "\n",
    "At this stage in the process it is required to cross validate the model i.e. check its accuracy to ensure that it can give accurate predictions when faced with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the data to ensure that our training and test sets are balanced when we perform the 80:20 split, training:test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frac keyword - specifies the number of rows to return in the rand\n",
    "# sample -> 1 returns all rows\n",
    "df_new = df_new.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create an instance of K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbutler/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['text'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['text'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.814097528986\n",
      "Confusion matrix:\n",
      "[[741 126]\n",
      " [112 520]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open('./models/multinomialnb_post_classifier.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating more features with N-grams\n",
    "\n",
    "The counts where generated using the \"bag of words\" approach which counts single instances of words. Using n-grams we can count phrases for example \"this is a phrase\" --> \"this is\" \"is a\" \"a phrase\"\n",
    "\n",
    "CountVectorizer can be instructed to use this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['text'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['text'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.775694290841\n",
      "Confusion matrix:\n",
      "[[797  70]\n",
      " [187 445]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open('./models/ngrams_multinomialnb_post_classifier.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "        input='ngram_range=(1, 2)', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "       ...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer('''ngram_range=(1, 2)''')),\n",
    "    ('tfidf_transformer', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['text'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['text'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.731420743199\n",
      "Confusion matrix:\n",
      "[[815  52]\n",
      " [237 395]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs exceptionally bad compared to the other two previous. An overall accuracy of 54% is recorded. We can disregard this model for the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes Model\n",
    "\n",
    "This algorithm focuses on the n-grams occurences rather than the counts. A vector of booleans representing the presence of absence of an n-gram. \n",
    "\n",
    "After some research I found that this model is said to perform better on shorter documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('classifier', BernoulliNB(binarize=0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=len(df_new), n_folds = 10)\n",
    "scores = [] #holds the score for each\n",
    "confusion = np.array([[0,0], [0,0]]) #initialize the confusion matrix\n",
    "\n",
    "for train_ind, test_ind in kf:\n",
    "    \n",
    "    #training data(x) and classification(y)\n",
    "    train_x = df_new.iloc[train_ind]['text'].values\n",
    "    train_y = df_new.iloc[train_ind]['OK'].values\n",
    "    \n",
    "    #testing training data\n",
    "    test_x = df_new.iloc[test_ind]['text'].values\n",
    "    test_y = df_new.iloc[test_ind]['OK'].values\n",
    "    \n",
    "    #train and predict each of the values\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    predictions = pipeline.predict(test_x)\n",
    "    \n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=1)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts classified: 1499\n",
      "Score: 0.532129996036\n",
      "Confusion matrix:\n",
      "[[843  24]\n",
      " [390 242]]\n"
     ]
    }
   ],
   "source": [
    "print('Total posts classified:', len(df_new))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall results for this experiment\n",
    "\n",
    "* NB classifier Bag of words --> 0.814\n",
    "* NB n-grams                 --> 0.776\n",
    "* TF-IDF                     --> 0.539\n",
    "* Bernoulli NB               --> 0.532\n",
    "\n",
    "The most successful model was the NB using the bag of words as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
